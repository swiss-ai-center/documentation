# audio-transcription

- [:material-account-group: Main author - HES-SO Valais-Wallis](https://www.hes-so.ch/swiss-ai-center/equipe)
- [:material-git: Code](https://github.com/swiss-ai-center/audio-transcription-service)
- [:material-kubernetes: Deployment configuration](https://github.com/swiss-ai-center/audio-transcription/tree/main/kubernetes)
- [:material-test-tube: Staging](https://audio-transcription-swiss-ai-center.kube-ext.isc.heia-fr.ch)
- [:material-factory: Production](https://audio-transcription-service.swiss-ai-center.ch)

## Description

!!! note

    More information about the service specification can be found in the
    [**Core concepts > Service**](../core-concepts/service.md) documentation.

This service uses Whisper tiny model from the transformers library to transcribe
the speach from an audio file and return the result as a JSON file. The JSON
contains a single field called "transcription", which holds the transcribed
text.

The API documentation is automatically generated by FastAPI using the OpenAPI
standard. A user friendly interface provided by Swagger is available under the
`/docs` route, where the endpoints of the service are described.

This simple service only has one route `/compute` that takes a mp3 or ogg file
as input, which will be transcribed.

## Environment variables

Check the
[**Core concepts > Service > Environment variables**](../core-concepts/service.md#environment-variables)
documentation for more details.

## Run the tests with Python

Check the
[**Core concepts > Service > Run the tests with Python**](../core-concepts/service.md#run-the-tests-with-python)
documentation for more details.

## Start the service locally

Check the
[**Core concepts > Service > Start the service locally**](../core-concepts/service.md#start-the-service-locally)
documentation for more details.
