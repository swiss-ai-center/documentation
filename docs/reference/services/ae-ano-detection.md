# ae-ano-detection

- [:material-account-group: Main author - HE-Arc](https://www.hes-so.ch/swiss-ai-center/equipe)
- [:material-git: Code](https://github.com/swiss-ai-center/ae-ano-detection-service)
- [:material-kubernetes: Deployment configuration](https://github.com/swiss-ai-center/ae-ano-detection-service/tree/main/model-serving/kubernetes)
- [:material-test-tube: Staging](https://ae-ano-detection-swiss-ai-center.kube.isc.heia-fr.ch)
- [:material-factory: Production](https://ae-ano-detection-service.swiss-ai-center.ch)

## Description

!!! note

    More information about the service specification can be found in the
    [**Core concepts > Service**](../core-concepts/service.md) documentation.

This service uses an autoencoder model to detect an anomaly in a time series.

The service is built in two steps:

1. [Model creation](#model-creation) - The creation of the model from the data
2. [Model serving](#model-serving) - The serving of the built model

## Model creation

The goal of this step is to prepare the data and train a new model. All further
commands are ran in the `model-creation` directory.

!!! info

    All following commands are done in the `model-creation` directory.

### Set up the environment

Set up the environment with the following commands.

```sh
# Generate the virtual environment
python3.11 -m venv .venv

# Activate the virtual environment
source .venv/bin/activate

# Install the requirements
pip install \
    --requirement requirements.txt \
    --requirement requirements-all.txt
```

### Run the experiment

Run a new training using the following commands.

```sh
# Export the MinIO S3 credentials (ask them to other members of the team)
export AWS_ACCESS_KEY_ID=***
export AWS_SECRET_ACCESS_KEY=***

# Pull the required data for the experiment from MinIO
dvc pull

# Reproduce the ML experiment with DVC
dvc repro
```

!!! note

    If you encounter a `libdevice not found at ./libdevice.10.bc` error message
    while utilizing an Nvidia GPU with CUDA, you should export the CUDA library path
    by executing the command:

    `export XLA_FLAGS=--xla_gpu_cuda_data_dir=/opt/cuda`

    Adjust the path accordingly. This step is necessary to enable successful
    GPU-based training for the model.

The DVC pipeline is described in the `dvc.yaml` file.

Each stage describes the dependencies and the outputs of the stage. Every time a
dependency of the experiment is updated, running `dvc repro` will run the stages
of the pipeline that are affected and keep the results in cache to speed up
future runs.

More information on their website:
[_Get Started: Data Pipelines_ - dvc.org](https://dvc.org/doc/start/data-management/data-pipelines).

### Push new data/results to MinIO

In order to push new results to MinIO, use the following commands (similar to
Git). **Note**: DVC automatically adds files that are specified in the
pipelines. In other words, there are no needs to explicitly add those files with
`dvc add`. Don't forget to then add the DVC metadata files to Git as well.

```sh
# Get the data status
dvc status

# Add the required files to DVC
dvc add <the files you would add to DVC>

# Push the data to DVC
dvc push
```

## Model serving

The goal of this step is to serve the model made in the previous step. All
further commands are ran in the `model-serving` directory.

The API documentation is automatically generated by FastAPI using the OpenAPI
standard. A user friendly interface provided by Swagger is available under the
`/docs` route, where the endpoints of the service are described.

This simple service only has one route `/compute` that takes an image as input,
which will be used to guess the number.

!!! info

    All following commands are done in the `model-serving` directory.

### Retrieve the model

Run the following command to get the model created from the previous step.

```sh
# Copy the model from the creation directory
cp ../model-creation/model/ae_model.h5 ./model/ae_model.h5
```

### Environment variables

Check the
[**Core concepts > Service > Environment variables**](../core-concepts/service.md#environment-variables)
documentation for more details.

### Start the service locally

Check the
[**Core concepts > Service > Start the service locally**](../core-concepts/service.md#start-the-service-locally)
documentation for more details.

### Run the tests with Python

Check the
[**Core concepts > Service > Run the tests with Python**](../core-concepts/service.md#run-the-tests-with-python)
documentation for more details.
